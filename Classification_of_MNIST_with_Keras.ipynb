{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification of MNIST with Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmulPatil/Case-Studies/blob/master/Classification_of_MNIST_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dhYPFBwap-w",
        "colab_type": "text"
      },
      "source": [
        "To Achieve two main objectives for this script to classify MNIST dataset,they are:\n",
        "\n",
        "\n",
        "*   Minimum number of parameters usage in the Neural Network\n",
        "*   Achieve high accuracy,Since its balanced dataset we will focus on accuracy as metrics to improve\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_uOi6YlZXl6",
        "colab_type": "code",
        "outputId": "f40322b4-b63c-49b5-cd1a-e49326e67f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "!pip install -U keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 26.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 7.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 8.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.2.5\n",
            "    Uninstalling Keras-2.2.5:\n",
            "      Successfully uninstalled Keras-2.2.5\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **Import Libraries and modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "outputId": "2480c5b2-6427-4e17-ea75-b02655935359",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add, BatchNormalization\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
        "from keras.layers import Activation\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from pylab import rcParams\n",
        "rcParams['figure.figsize'] = 15, 12\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "outputId": "583ba6c1-0afa-4a99-f81c-59ba7a0332f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "dc45f642-2f1e-47c6-80fa-8c183200dcba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f16f4d3c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSRB2IAnCDiTx/65XcTNOWsh5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert data type to 32-bit precision which is required for  training a neural network\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "7a8430a7-e952-46f9-aa26-77bd26bc5660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueFZNqjEhS4Q",
        "colab_type": "text"
      },
      "source": [
        "**Initial Structure of the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvC9B0OIgf6k",
        "colab_type": "text"
      },
      "source": [
        "lets build a structure where we can cover atleast Receptive Field of around 28 since we have 28 image size for Mnist dataset.\n",
        "And to cover more iteration at one go we are clubbing summary and training logs altogether in one cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "outputId": "5f8be751-d7b6-44ff-b174-0d01b182661d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(Convolution2D(24, 3, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 4))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=32, epochs=15, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (3, 3), activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 24, 24, 16)        1168      \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 22, 22, 24)        3480      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 11, 11, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 11, 11, 10)        250       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 9, 9, 32)          2912      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 4, 4, 10)          330       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 1, 1, 10)          1610      \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 9,830\n",
            "Trainable params: 9,830\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.2141 - accuracy: 0.9318 - val_loss: 0.0744 - val_accuracy: 0.9773\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0790 - accuracy: 0.9761 - val_loss: 0.0528 - val_accuracy: 0.9838\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0594 - accuracy: 0.9811 - val_loss: 0.0647 - val_accuracy: 0.9808\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0493 - accuracy: 0.9843 - val_loss: 0.0397 - val_accuracy: 0.9858\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0439 - accuracy: 0.9865 - val_loss: 0.0352 - val_accuracy: 0.9875\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0388 - accuracy: 0.9879 - val_loss: 0.0343 - val_accuracy: 0.9895\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0347 - accuracy: 0.9891 - val_loss: 0.0418 - val_accuracy: 0.9875\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0299 - accuracy: 0.9901 - val_loss: 0.0367 - val_accuracy: 0.9888\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0282 - accuracy: 0.9910 - val_loss: 0.0367 - val_accuracy: 0.9880\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 0.0343 - val_accuracy: 0.9896\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.0343 - val_accuracy: 0.9898\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 11s 180us/step - loss: 0.0225 - accuracy: 0.9923 - val_loss: 0.0372 - val_accuracy: 0.9883\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.0286 - val_accuracy: 0.9915\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0351 - val_accuracy: 0.9897\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0320 - val_accuracy: 0.9898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f16ce1434a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9My2jUvWfdIR",
        "colab_type": "code",
        "outputId": "045dab38-90a7-4b99-e9b5-6bb968754d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Result of first iteration\n",
        "print(model.evaluate(X_test, Y_test, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.03203787759745319, 0.989799976348877]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1dvZRYQg3ga",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of First model came around 98.89% for about 10 epochs with only 9,830 parameters to train ,Nice metrics for first iteration of experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieyoiwAdhj2i",
        "colab_type": "text"
      },
      "source": [
        "#Second Iteration of Experiment:\n",
        "lets try to increase the batch size & include Batchnorm & reduce the channels to the above structure and observe any improvement in test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtsH-lLk-eLb",
        "colab_type": "code",
        "outputId": "028e3faa-4b1b-4e19-e8d5-3ff6939fd4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential() \n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(14, 3, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Convolution2D(10, 4))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, batch_size=256, epochs=15, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, (3, 3), activation=\"relu\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 24, 24, 12)        876       \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 12)        48        \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 22, 22, 14)        1526      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 11, 11, 14)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 11, 11, 10)        150       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 4, 4, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 4, 4, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 1, 1, 10)          1610      \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 6,028\n",
            "Trainable params: 5,948\n",
            "Non-trainable params: 80\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.5500 - accuracy: 0.8436 - val_loss: 2.2208 - val_accuracy: 0.2021\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1177 - accuracy: 0.9672 - val_loss: 0.2257 - val_accuracy: 0.9349\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0781 - accuracy: 0.9776 - val_loss: 0.0703 - val_accuracy: 0.9789\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0604 - accuracy: 0.9825 - val_loss: 0.0604 - val_accuracy: 0.9809\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0505 - accuracy: 0.9853 - val_loss: 0.0557 - val_accuracy: 0.9815\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0437 - accuracy: 0.9871 - val_loss: 0.0477 - val_accuracy: 0.9849\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0386 - accuracy: 0.9884 - val_loss: 0.0460 - val_accuracy: 0.9858\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.0478 - val_accuracy: 0.9843\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0310 - accuracy: 0.9910 - val_loss: 0.0409 - val_accuracy: 0.9867\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0279 - accuracy: 0.9917 - val_loss: 0.0404 - val_accuracy: 0.9871\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0254 - accuracy: 0.9926 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.0236 - accuracy: 0.9931 - val_loss: 0.0589 - val_accuracy: 0.9815\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0215 - accuracy: 0.9936 - val_loss: 0.0420 - val_accuracy: 0.9873\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 0.0392 - val_accuracy: 0.9877\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0421 - val_accuracy: 0.9877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f16c79d69e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOmXPqJyg9rh",
        "colab_type": "code",
        "outputId": "05199e4c-ae04-4b72-d5be-283bf4788579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Result of first iteration\n",
        "print(model.evaluate(X_test, Y_test, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.042138277958368414, 0.9876999855041504]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahC_4XP8h41D",
        "colab_type": "text"
      },
      "source": [
        "It wasn't an improvement over the last structure we build but the model did pretty good with less number of parameters involved\n",
        "####so just to achive accuracy greater then 99.0% on unseen dataset we make below changes to the architecture and the parameters of the model\n",
        "\n",
        "\n",
        "*   Normalize the Image Initially\n",
        "*   Increase number of parameters of the model\n",
        "*   Reduce Learning rate once the Accuracy doesn't show any improvements\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdpjmeF7xqHx",
        "colab_type": "text"
      },
      "source": [
        "#Third Iteration of Experiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMTv14HcdqC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Image Normalization\n",
        "gen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "test_gen = ImageDataGenerator()\n",
        "train_generator = gen.flow(X_train, Y_train, batch_size=32)\n",
        "test_generator = gen.flow(X_test, Y_test, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "eb273ecb-9b56-4d26-b3cd-912435b40934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(16, 3, 3,  input_shape=(28,28,1))) #26\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(32, 3, 3)) #24\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Convolution2D(10, 1, 1)) #22\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#11\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3))#9\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3))#7\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3))#5\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3))#3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(10, 4, 4))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(train_generator,  epochs=15, \n",
        "                    validation_data=test_generator,  callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), input_shape=(28, 28, 1...)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1))`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (4, 4))`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_30 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 24, 24, 10)        330       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 24, 24, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 24, 24, 10)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 10, 10, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 10, 10, 16)        64        \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 10, 10, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 8, 8, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 8, 8, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 6, 6, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 6, 6, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 6, 6, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 4, 4, 16)          64        \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 1, 1, 10)          2570      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 1, 1, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1, 1, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 16,644\n",
            "Trainable params: 16,380\n",
            "Non-trainable params: 264\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 35s 18ms/step - loss: 0.5607 - accuracy: 0.8370 - val_loss: 0.0307 - val_accuracy: 0.9837\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3905 - accuracy: 0.8726 - val_loss: 0.0703 - val_accuracy: 0.9901\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3556 - accuracy: 0.8812 - val_loss: 0.0144 - val_accuracy: 0.9902\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3388 - accuracy: 0.8828 - val_loss: 0.0105 - val_accuracy: 0.9892\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3335 - accuracy: 0.8837 - val_loss: 0.0088 - val_accuracy: 0.9924\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3222 - accuracy: 0.8860 - val_loss: 0.0024 - val_accuracy: 0.9941\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3208 - accuracy: 0.8865 - val_loss: 0.0096 - val_accuracy: 0.9931\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3126 - accuracy: 0.8888 - val_loss: 0.0027 - val_accuracy: 0.9928\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3070 - accuracy: 0.8905 - val_loss: 0.0040 - val_accuracy: 0.9934\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3120 - accuracy: 0.8882 - val_loss: 0.0046 - val_accuracy: 0.9929\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.3073 - accuracy: 0.8887 - val_loss: 0.0765 - val_accuracy: 0.9937\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2995 - accuracy: 0.8921 - val_loss: 0.0052 - val_accuracy: 0.9930\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2980 - accuracy: 0.8928 - val_loss: 0.0293 - val_accuracy: 0.9934\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2964 - accuracy: 0.8918 - val_loss: 0.0017 - val_accuracy: 0.9938\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.2916 - accuracy: 0.8939 - val_loss: 0.0411 - val_accuracy: 0.9941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f16c64159e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "outputId": "8d53d215-8d33-4793-9c7e-751281522713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model.evaluate(X_test, Y_test, verbose=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.02410577271617949, 0.9940999746322632]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eCZy_NfwFBy",
        "colab_type": "text"
      },
      "source": [
        "**The Final Accuracy of 99.409% reached,with around 16K parameters in the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSzSEDNJqEFg",
        "colab_type": "text"
      },
      "source": [
        "Let us see count of images  predicted correctly/incorrectly by the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDTDkflxoZwo",
        "colab_type": "code",
        "outputId": "0b7e45dd-9bda-4645-a9e4-bde43ca93498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# see which we predicted correctly and which not\n",
        "pred=model.predict(X_test)\n",
        "pred_digits=np.argmax(pred,axis=1)\n",
        "actual_labelled = np.argmax(Y_test,axis=1)\n",
        "correct_indices = np.nonzero(pred_digits == actual_labelled)[0]\n",
        "incorrect_indices = np.nonzero(pred_digits != actual_labelled)[0]\n",
        "print(\"classified correctly :- \",len(correct_indices) ,\" classified incorrectly: -\" ,len(incorrect_indices),)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classified correctly :-  9941  classified incorrectly: - 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubgeMWXhq2A2",
        "colab_type": "text"
      },
      "source": [
        "Now let us see which are Correctly classified images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "outputId": "8925d13d-2693-439e-b235-09313eb4bf63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "# adapt figure size to accomodate 18 subplots\n",
        "plt.rcParams['figure.figsize'] = (7,14)\n",
        "# plot 9 correct predictions\n",
        "for i, correct in enumerate(correct_indices[:9]):\n",
        "    plt.subplot(6,3,i+1)\n",
        "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\n",
        "      \"Predicted: {}, Truth: {}\".format(pred_digits[correct],\n",
        "                                        y_test[correct]))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAGTCAYAAAD3IB/vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD6cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 504x1008 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDuKBPPHrAp1",
        "colab_type": "text"
      },
      "source": [
        "Now let us see which are missclassified images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DDxEiUSpjVi",
        "colab_type": "code",
        "outputId": "4ff44927-6b60-4e03-de81-dbe6fd52fa01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "source": [
        "\n",
        "# plot 9 incorrect predictions\n",
        "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
        "    plt.subplot(6,3,i+10)\n",
        "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
        "    plt.title(\n",
        "      \"Predicted {}, Truth: {}\".format(pred_digits[incorrect], \n",
        "                                       y_test[incorrect]))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAGTCAYAAAD+y7+VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npHjktgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x1008 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4wrH-WxwdUG",
        "colab_type": "text"
      },
      "source": [
        "##This is Starter Script for Image classification.In the Next script we will Work on Cifar10 Dataset.\n",
        "Note: Some of the regularization technique's are ignored for this case, like image augmentation technique's which would help in reducing number of parameters in the model aswell as achieve high accuracy simulatneously which would be carried out in the next script for difficult tasks."
      ]
    }
  ]
}