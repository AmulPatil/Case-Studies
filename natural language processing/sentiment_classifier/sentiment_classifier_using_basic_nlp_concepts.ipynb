{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Sentiment Classification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKRQH25bKwWM",
        "colab_type": "text"
      },
      "source": [
        "<h2>Sentiment Classification on Movie Reviews:</h2>\n",
        "To classify whither a text sentence is positive/negative is pretty hard for computers to understand because they don't know how to process human language context.So inorder to teach machine's human language context we have to train them accordingly.<br />\n",
        "Since this is beginning of journey to deepdive into Natural language processing,let's begin with sentiment classification problem with techniques which are quite old compared to current techniques which are used nowadays.\n",
        "Overview of Techniques used in this script \n",
        "\n",
        "*   CountVectorizer,TF-IDF Vectorizer\n",
        "*   StopWord,Lemmatization,Stemming,N-Gram\n",
        "\n",
        "\n",
        "Dataset for the movie reviews are taken from <strong><em>http://ai.stanford.edu/~amaas/data/sentiment/</em></strong>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJzvT10BKwWU",
        "colab_type": "text"
      },
      "source": [
        "<h3>Import Libraries</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNH_Z1dlKwWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import scikitplot as skplt\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "english_stop_words = stopwords.words('english')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGJ-69WgKwWq",
        "colab_type": "text"
      },
      "source": [
        "<h3>Function to find optimal parameters of ML Algorithm.</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZII8hITKwWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grid search to find the best model and accuracy for our data.\n",
        "def gridsearch_best_model_and_accuracy(model, params, X, y):\n",
        "    \n",
        "    grid = GridSearchCV(model, # the model to grid search\n",
        "    params, # the parameter set to try\n",
        "    error_score=0.,\n",
        "    n_jobs =-1,\n",
        "    cv=5) # if a parameter set raises an error, continue and set the performance as a big, fat\n",
        "    grid.fit(X, y) # fit the model and parameters\n",
        "    # our classical metric for performance\n",
        "    print (\"Best Accuracy: {}\".format(grid.best_score_))\n",
        "    # the best parameters that caused the best accuracy\n",
        "    print (\"Best Parameters: {}\".format(grid.best_params_))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbdbJsp2KwW0",
        "colab_type": "text"
      },
      "source": [
        "<h3>Functions to Preprocess the Text data </h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVfqAPtmKwW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_reviews(reviews):\n",
        "    \n",
        "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
        "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
        "    \n",
        "    return reviews\n",
        "\n",
        "def remove_stop_words(corpus):\n",
        "    removed_stop_words = []\n",
        "    for review in corpus:\n",
        "        removed_stop_words.append(\n",
        "            ' '.join([word for word in review.split() \n",
        "                      if word not in english_stop_words])\n",
        "        )\n",
        "    return removed_stop_words\n",
        "\n",
        "def get_stemmed_text(corpus):\n",
        "    stemmer = PorterStemmer()\n",
        "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
        "\n",
        "\n",
        "def get_lemmatized_text(corpus):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iP4ZcXUKwW7",
        "colab_type": "text"
      },
      "source": [
        "<h3>Load the data into the python environment</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-7yuDZ9KwW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_train = []\n",
        "for line in open('full_train.txt', 'r',encoding=\"utf8\"):\n",
        "    \n",
        "    reviews_train.append(line.strip())\n",
        "    \n",
        "reviews_test = []\n",
        "for line in open('full_test.txt', 'r',encoding=\"utf8\"):\n",
        "    \n",
        "    reviews_test.append(line.strip())\n",
        "    \n",
        "train_target = [1 if i < 12500 else 0 for i in range(25000)]\n",
        "test_target = [1 if i < 12500 else 0 for i in range(25000)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9yeRVkgKwXC",
        "colab_type": "text"
      },
      "source": [
        "<h3>Explore the dataset and look for unwanted strings,number symbols,etc and remove them accordingly</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2qVgABtKwXD",
        "colab_type": "code",
        "outputId": "7592bd14-d57f-426e-c5c8-908d5e3bf177",
        "colab": {}
      },
      "source": [
        "reviews_train[0:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!',\n",
              " 'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWO-5xRFKwXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
        "NO_SPACE = \"\"\n",
        "SPACE = \" \"\n",
        "reviews_train_clean = preprocess_reviews(reviews_train)\n",
        "reviews_test_clean = preprocess_reviews(reviews_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGB54VyhKwXR",
        "colab_type": "text"
      },
      "source": [
        "<h3>Lets build a baseline model for classification</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnjHF60LKwXS",
        "colab_type": "code",
        "outputId": "ef525d01-d5f3-4983-c582-110b02ae8567",
        "colab": {}
      },
      "source": [
        "#(cleaned data introduced to the default setting of model)\n",
        "baseline_vectorizer = CountVectorizer(binary=True)\n",
        "baseline_vectorizer.fit(reviews_train_clean)\n",
        "X_train_baseline = baseline_vectorizer.transform(reviews_train_clean)\n",
        "X_test_baseline = baseline_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "\n",
        "svm = LinearSVC(random_state=10,max_iter=2000)\n",
        "svm.fit(X_train_baseline, train_target)\n",
        "print (\"Accuracy of %s on Unseen dataset\" \n",
        "       % ( accuracy_score(test_target, svm.predict(X_test_baseline))))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of 0.848 on Unseen dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX9BT8pDKwXY",
        "colab_type": "text"
      },
      "source": [
        "<h3>Lets see how much of performance increase we would get by finetuning baseline model</h3>\n",
        "In SVM we have finetuned the penalty parameter,basic info regarding the parameter:<br />\n",
        "C is a regularization parameter that controls the trade off between achieving a low training error\n",
        "and a low testing error ,that is the ability to generalize your classifier to unseen data.\n",
        "Consider the objective function of a linear SVM : min |w|^2+C∑ξ. If your C is too large the optimization\n",
        "algorithm will try to reduce |w| as much as possible leading to a hyperplane which tries to classify each \n",
        "training example correctly.<br /> Doing this will lead to loss in generalization properties of the classifier.\n",
        "On the other hand if your C is too small then you give your objective function a certain freedom to increase |w| a lot, \n",
        "which will lead to large training error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ndbp5RQEKwXZ",
        "colab_type": "code",
        "outputId": "3c1e352f-7755-4d87-b800-788529f731ad",
        "colab": {}
      },
      "source": [
        "params = {'C':[ 0.05, 0.1, 0.3]\n",
        " }\n",
        "svm = LinearSVC(random_state=10)\n",
        "    \n",
        "gridsearch_best_model_and_accuracy(svm,params,X_train_baseline, train_target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy: 0.85076\n",
            "Best Parameters: {'C': 0.05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-gexbk1KwXf",
        "colab_type": "code",
        "outputId": "fb3c9994-63e8-45ff-fab5-55f3028d42ed",
        "colab": {}
      },
      "source": [
        "svm_baseline = LinearSVC(random_state=10,C=0.05)\n",
        "svm_baseline.fit(X_train_baseline, train_target)\n",
        "print (\"Accuracy of %s on Unseen dataset\" \n",
        "       % ( accuracy_score(test_target, svm_baseline.predict(X_test_baseline))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of 0.8676 on Unseen dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwVKc75JKwXk",
        "colab_type": "text"
      },
      "source": [
        "<h4>Increase in Accuracy by 1.96%(finetuned 0.8676 - baseline 0.848)  after finetuning the model compared to baseline model</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBKU3U8LKwXl",
        "colab_type": "text"
      },
      "source": [
        "<h5>Lets try some of the basic data cleaning process like removing Stopwords,Lemmatization,Stemming whither these will help in improvement in performance.</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCwOO7HTKwXm",
        "colab_type": "code",
        "outputId": "e2fb9e2b-64f0-45ed-b24e-31d039e0ca07",
        "colab": {}
      },
      "source": [
        "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
        "no_stop_words_test = remove_stop_words(reviews_test_clean)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(no_stop_words_train)\n",
        "X_train = cv.transform(no_stop_words_train)\n",
        "X_test = cv.transform(no_stop_words_test)\n",
        "params = {\n",
        "          'C':[ 0.05, 0.1, 0.3]\n",
        " }\n",
        "svm = LinearSVC(random_state=10)\n",
        "    \n",
        "gridsearch_best_model_and_accuracy(svm,params,X_train, train_target)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy: 0.84788\n",
            "Best Parameters: {'C': 0.05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1dt6GC2KwXt",
        "colab_type": "code",
        "outputId": "f46ac92c-3d87-418f-aef7-c423816f2f33",
        "colab": {}
      },
      "source": [
        "svm = LinearSVC(random_state=10,C=0.05)\n",
        "svm.fit(X_train, train_target)\n",
        "print (\"Accuracy for %s\" \n",
        "       % ( accuracy_score(test_target, svm.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0.86644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANqBGgYCKwXy",
        "colab_type": "text"
      },
      "source": [
        "<h5>Accuracy decreased as compared to previous improvement(0.8676) .lets try other rest of the cleaning process</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA3bbGffKwXz",
        "colab_type": "code",
        "outputId": "54202e93-dc06-490b-b57f-fed1e596ebc3",
        "colab": {}
      },
      "source": [
        "stemmed_reviews_train = get_stemmed_text(reviews_train_clean)\n",
        "stemmed_reviews_test = get_stemmed_text(reviews_test_clean)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(stemmed_reviews_train)\n",
        "X_train = cv.transform(stemmed_reviews_train)\n",
        "X_test = cv.transform(stemmed_reviews_test)\n",
        "params = {\n",
        "          'C':[ 0.05, 0.1, 0.3]\n",
        " }\n",
        "svm = LinearSVC(random_state=10)\n",
        "    \n",
        "gridsearch_best_model_and_accuracy(svm,params,X_train, train_target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy: 0.84392\n",
            "Best Parameters: {'C': 0.05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qinMkjooKwX4",
        "colab_type": "code",
        "outputId": "31773c06-652a-499a-db0d-af49b761ca44",
        "colab": {}
      },
      "source": [
        "svm = LinearSVC(random_state=10,C=0.05)\n",
        "svm.fit(X_train, train_target)\n",
        "print (\"Accuracy for %s\" \n",
        "       % ( accuracy_score(test_target, svm.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0.8618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37PvGB_KwX8",
        "colab_type": "text"
      },
      "source": [
        "<h5>Accuracy decreased as compared to previous improvement(0.8676) .lets try other rest of the cleaning process</h5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2LBGuZHKwX9",
        "colab_type": "text"
      },
      "source": [
        "<h5>It seems data cleaning is not able to improve our results.lets try all preprocessing steps on data cleaning process</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1SVWafOKwY8",
        "colab_type": "code",
        "outputId": "dddfa845-2dcd-4c1a-b32a-f5774347ff0b",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "          'C':[0.01, 0.05, 0.1]\n",
        " }\n",
        "no_stop_words_train = remove_stop_words(reviews_train_clean)\n",
        "no_stop_words_test = remove_stop_words(reviews_test_clean)\n",
        "stemmed_reviews_train = get_stemmed_text(no_stop_words_train)\n",
        "stemmed_reviews_test = get_stemmed_text(no_stop_words_test)\n",
        "preprocessing_train = get_lemmatized_text(stemmed_reviews_train)\n",
        "preprocessing_test = get_lemmatized_text(stemmed_reviews_test)\n",
        "\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(preprocessing_train)\n",
        "X_train = cv.transform(preprocessing_train)\n",
        "X_test = cv.transform(preprocessing_test)\n",
        "svm_text = LinearSVC(random_state=10)\n",
        "\n",
        "gridsearch_best_model_and_accuracy(svm_text,params,X_train, train_target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy: 0.85712\n",
            "Best Parameters: {'C': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMXTM4KiKwZE",
        "colab_type": "code",
        "outputId": "a26fe546-bc2c-4c23-cdfb-ec453440ec0a",
        "colab": {}
      },
      "source": [
        "svm = LinearSVC(random_state=10,C=0.01)\n",
        "svm.fit(X_train, train_target)\n",
        "print (\"Accuracy for %s\" \n",
        "       % ( accuracy_score(test_target, svm.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0.8736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6gSrp6qKwZK",
        "colab_type": "text"
      },
      "source": [
        "<h5>Accuracy Increased as compared to previous improvement by 0.60%.lets try ngrams and remove the above time consuming data cleaning methods</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDDMatGlKwZL",
        "colab_type": "code",
        "outputId": "0da3465a-ac02-4183-8ddd-2f441f773dd0",
        "colab": {}
      },
      "source": [
        "#stop_words = ['in', 'of', 'at', 'a', 'the']\n",
        "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3))\n",
        "ngram_vectorizer.fit(reviews_train_clean)\n",
        "X_train = ngram_vectorizer.transform(reviews_train_clean)\n",
        "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
        "\n",
        "params = {\n",
        "          'C':[0.01, 0.05, 0.1]\n",
        "          \n",
        " }\n",
        "svm = LinearSVC(random_state=10)\n",
        "    \n",
        "gridsearch_best_model_and_accuracy(svm,params,X_train, train_target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy: 0.88356\n",
            "Best Parameters: {'C': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD0xZQ1jKwZT",
        "colab_type": "code",
        "outputId": "91632059-85e6-4c90-e126-f433f11bcc4c",
        "colab": {}
      },
      "source": [
        "svm = LinearSVC(random_state=10,C=0.01)\n",
        "svm.fit(X_train, train_target)\n",
        "print (\"Accuracy for %s\" \n",
        "       % ( accuracy_score(test_target, svm.predict(X_test))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 0.8984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhVP1NpFKwZY",
        "colab_type": "text"
      },
      "source": [
        "<h5>Lets try TF-IDF concept along with Ngrams to vectorize our data to see whither we can beat 89.84% accuracy</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgC5fA65KwZY",
        "colab_type": "code",
        "outputId": "180abc33-2db0-44aa-9809-77c4d195ad3a",
        "colab": {}
      },
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2),use_idf=True)\n",
        "tfidf_vectorizer.fit(reviews_train_clean)\n",
        "X_train = tfidf_vectorizer.transform(reviews_train_clean)\n",
        "X_test = tfidf_vectorizer.transform(reviews_test_clean)\n",
        "params = {\n",
        "          'C':[ 0.1, 0.3,0.4,0.5,0.6]\n",
        " }\n",
        "svm_tfidf = LinearSVC(random_state=10)\n",
        "    \n",
        "gridsearch_best_model_and_accuracy(svm_tfidf,params,X_train, train_target)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Accuracy: 0.87844\n",
            "Best Parameters: {'C': 0.5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKoNCEI5KwZd",
        "colab_type": "code",
        "outputId": "ed388c1f-ba6e-416d-863f-febcf586a2cb",
        "colab": {}
      },
      "source": [
        "svm_tfidf = LinearSVC(random_state=10,C=0.5)\n",
        "svm_tfidf.fit(X_train, train_target)\n",
        "print (\"Accuracy for %s\" \n",
        "       % ( accuracy_score(test_target, svm_tfidf.predict(X_test))*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for 90.064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4llgSkPWKwZh",
        "colab_type": "text"
      },
      "source": [
        "<h4>The final accuracy for text sentiment classification came around 90.06% using TF-IDF</h4>\n",
        "<h5>1. Increase in accuracy by 0.224% as compared to countvectorization<br />\n",
        "2. Stopwords,stemming,lemmatization din't help much in our case<br />\n",
        "3. Concept of ngrams & tunning the penalty parameter of SVM helped to get Best Accuracy<br />\n",
        "4. 5.264% increase in accuracy as compared to baseline model.</h5>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jPsWLujKwZi",
        "colab_type": "code",
        "outputId": "df2561c3-4ef1-47b2-d9c5-bcd625ba7f2b",
        "colab": {}
      },
      "source": [
        "print(classification_report(test_target, svm_tfidf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.90      0.90     12500\n",
            "           1       0.90      0.90      0.90     12500\n",
            "\n",
            "    accuracy                           0.90     25000\n",
            "   macro avg       0.90      0.90      0.90     25000\n",
            "weighted avg       0.90      0.90      0.90     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obdm5s9hKwZm",
        "colab_type": "text"
      },
      "source": [
        "<strong><em>Precision:</em></strong>“When it predicts the positive result, how often is it correct?”<br />\n",
        "<strong><em>Recall:</em></strong> “When it is actually the positive result, how often does it predict correctly?”<br />\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a55Rimb_KwZn",
        "colab_type": "code",
        "outputId": "e2e55d39-1529-4a98-b133-bf52c1eb05c9",
        "colab": {}
      },
      "source": [
        "skplt.metrics.plot_confusion_matrix(\n",
        "    test_target, \n",
        "    svm_tfidf.predict(X_test),\n",
        "    figsize=(4,4))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x1dc99cbbfc8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE9r8Fq6KwZq",
        "colab_type": "text"
      },
      "source": [
        "<h4> First 6 Feature's co-efficients which contibutes for positive & negative reviews in IMDB </h4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r0zSBe9KwZr",
        "colab_type": "code",
        "outputId": "ce084e12-eccf-4284-9e26-4493ca4724cd",
        "colab": {}
      },
      "source": [
        "feature_to_coef = {\n",
        "    word: coef for word, coef in zip(\n",
        "        tfidf_vectorizer.get_feature_names(), svm_tfidf.coef_[0]\n",
        "    )\n",
        "}\n",
        "print('Contribution for Positive Reviews')\n",
        "for best_positive in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:6]:print (best_positive)\n",
        "print('Contribution for Negative Reviews')\n",
        "print(\"\\n\\n\")\n",
        "for best_negative in sorted(feature_to_coef.items(), key=lambda x: x[1])[:6]:print (best_negative)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contribution for Positive Reviews\n",
            "('great', 3.865311287273291)\n",
            "('excellent', 3.2035549017072382)\n",
            "('perfect', 2.506533970257332)\n",
            "('wonderful', 2.43069456517306)\n",
            "('fun', 2.249218218203249)\n",
            "('amazing', 2.1479506250868106)\n",
            "Contribution for Negative Reviews\n",
            "\n",
            "\n",
            "\n",
            "('worst', -4.072753270965381)\n",
            "('bad', -4.004675511804091)\n",
            "('awful', -3.4326282813211333)\n",
            "('boring', -3.2191988533498925)\n",
            "('the worst', -3.162329177967824)\n",
            "('poor', -3.096018355072262)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5drkSMKULAYB",
        "colab_type": "text"
      },
      "source": [
        "**Next Version of notebook will be containing some of advance technique like Word Embedding via Word2Vec and Glove embeddings which are part of transfer learning.And later we will go through with transfer leaning via ULMFIT, BERT,ROBERTA and cross verify whither there is any improvements in the final results**"
      ]
    }
  ]
}